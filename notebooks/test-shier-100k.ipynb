{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "687b5507-1b39-4e37-a126-fc3b7f00fdb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.18 (main, Jun  5 2025, 08:13:51) [Clang 14.0.6 ]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d71e2a3-6785-4b91-894a-976b761c51e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "from os.path import join as j_\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# loading all packages here to start\n",
    "from uni import get_encoder\n",
    "from uni.downstream.extract_patch_features import extract_patch_features_from_dataloader\n",
    "from uni.downstream.eval_patch_features.linear_probe import eval_linear_probe\n",
    "from uni.downstream.eval_patch_features.fewshot import eval_knn, eval_fewshot\n",
    "from uni.downstream.eval_patch_features.protonet import ProtoNet, prototype_topk_vote\n",
    "from uni.downstream.eval_patch_features.metrics import get_eval_metrics, print_metrics\n",
    "from uni.downstream.utils import concat_images\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26eaf7e9-9dfa-4439-9f7a-20383f6dc1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uni import get_encoder\n",
    "model, transform = get_encoder(enc_name='uni2-h', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e674a8e8-b22d-4835-9832-f71047573f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot = '../assets/data/CRC100K/'\n",
    "assert os.path.isdir('../assets/data/CRC100K/NCT-CRC-HE-100K-NONORM')\n",
    "assert os.path.isdir('../assets/data/CRC100K/CRC-VAL-HE-7K')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8524151-482f-44d1-84fd-e4f1523ac35c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|███▌                                                                                                 | 14/391 [1:07:47<30:25:24, 290.52s/it]\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x1110157e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/UNI/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/envs/UNI/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/anaconda3/envs/UNI/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/opt/anaconda3/envs/UNI/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/opt/anaconda3/envs/UNI/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/opt/anaconda3/envs/UNI/lib/python3.10/selectors.py\", line 416, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from uni.downstream.extract_patch_features import extract_patch_features_from_dataloader\n",
    "\n",
    "# get path to example data\n",
    "start = time.time()\n",
    "dataroot = '../assets/data/CRC100K/'\n",
    "\n",
    "# create some image folder datasets for train/test and their data laoders\n",
    "train_dataset = torchvision.datasets.ImageFolder(j_(dataroot, 'NCT-CRC-HE-100K-NONORM'), transform=transform)\n",
    "test_dataset = torchvision.datasets.ImageFolder(j_(dataroot, 'CRC-VAL-HE-7K'), transform=transform)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=False, num_workers=16)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=256, shuffle=False, num_workers=16)\n",
    "\n",
    "# extract patch features from the train and test datasets (returns dictionary of embeddings and labels)\n",
    "train_features = extract_patch_features_from_dataloader(model, train_dataloader)\n",
    "test_features = extract_patch_features_from_dataloader(model, test_dataloader)\n",
    "\n",
    "# convert these to torch\n",
    "train_feats = torch.Tensor(train_features['embeddings'])\n",
    "train_labels = torch.Tensor(train_features['labels']).type(torch.long)\n",
    "test_feats = torch.Tensor(test_features['embeddings'])\n",
    "test_labels = torch.Tensor(test_features['labels']).type(torch.long)\n",
    "elapsed = time.time() - start\n",
    "print(f'Took {elapsed:.03f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590b139c-a922-4bd6-9362-0239ca9bb4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
